<div class="container">
	<div class="row">
		<ul class="nav nav-tabs">
			<li class="nav-item"
			 		routerLinkActive="active"
					[routerLinkActiveOptions]="{exact: true}">
    		<a class="nav-link"
					 [routerLink]="[{ outlets: {info: ['collection'] } }]">Collection Info</a>
    	</li>
			<button type="button"
										class="btn btn-outline-primary btn-circle"
										placement="right-bottom"
										ngbPopover="The collection information shows on which data the newspaper model was trained.
				To compare the language of newspapers it is important to cover a similar amount of articles from a comparable time frame.
				The higher the number of articles  used for training, the more reliable is the model."
										popoverTitle="Collection Information"
										popover-class="increase-popover-width">
				?
			</button>
			<li class="nav-item"
			 		routerLinkActive="active">
			 	<a class="nav-link"	
			 		 [routerLink]="[{ outlets: {info: ['model']}}]">Model Info</a>
			</li>
			<button type="button"
										class="btn btn-outline-primary btn-circle"
										placement="right-bottom"
										ngbPopover="In a word embedding model words are represented as vectors. This representation is learned by looking at the context of words in a large collections of documents.
				Different methods and their parameters lead to different embedding models. For comparability purposes, these parameters are published here.
										For more information on how a model is trained, have a look here."
										popoverTitle="Model Information"
										>
				?
			</button>
			<li class="nav-item"
			 		routerLinkActive="active"
					[routerLinkActiveOptions]="{exact: true}">
			 	<a class="nav-link"	
			 		 [routerLink]="[{ outlets: {info: ['reliability']}}]">Reliability</a>
			</li>
			<button type="button"
										class="btn btn-outline-primary btn-circle"
										placement="right-bottom"
										ngbPopover="To get a feeling on how well a model captures semantic and grammatical relationships between words, an analogy task developed by Google (Mikolov et al., 2013b) is applied. It contains about 20000 analogies such as Paris is to France as Berlin is to Germany. The task is to find the last word, e.g Germany in this example.
										The analogy test dataset contains 14 different semantic and morphological categories. As a reference, a model trained on a 6B Google News corpus (window 10) reaches an accuracy of 24.0 (semantic) and 64 (syntactic tasks)."
										popoverTitle="Analogy Test">
				?
			</button>
		</ul>
	</div>
	<div class="row">
		<div class="col-xs-12 col-sm-10 col-md-8 col-sm-offset-1 col-md-offset-2">
			<br>
			<router-outlet name="info"></router-outlet>
		</div>
	</div>
</div>
